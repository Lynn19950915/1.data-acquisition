
Lecture 05　資料儲檔(1)

--------------------------------------------------------------------------------

5.1　.txt檔

from urllib import request
from bs4 import BeautifulSoup
import os

#新增一資料夾存放檔案
dir="C:/PyETL"
#檢查:若無則創建、有則存入
if not os.path.exists(dir):
    os.mkdir(dir)

headers={"User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36"}
url="https://www.ptt.cc/bbs/joke/index.html"

req=request.Request(url=url,headers=headers)
res=request.urlopen(req)
soup=BeautifulSoup(res,"html.parser")

#開檔寫入(w-mode)
file=open("%s/TXT.txt"%(dir)),"w",encoding="utf-8")
#以字串型態寫入檔案
file.write(str(soup))
file.close()


--------------------------------------------------------------------------------

5.2　.csv檔:內迴圈

from urllib import request
from bs4 import BeautifulSoup
import os

#新增一資料夾存放檔案
dir="C:/PyETL"
#檢查:若無則創建、有則存入
if not os.path.exists(dir):
    os.mkdir(dir)

headers={"User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36"}
url="https://www.ptt.cc/bbs/joke/index.html"
req=request.Request(url=url,headers=headers)
res=request.urlopen(req)
soup=BeautifulSoup(res,"html.parser")

#輸出所有文章標題及網址
target=soup.findAll("div",{"class":"title"})
for item in target:
    title=item.a.text
    url="https://www.ptt.cc"+item.a['href']

    #內迴圈開檔，附加(a-mode)續寫
    file=open("%s/CSV.csv"%(dir),"a",encoding="utf-8")
    file.write(title+url+"\n")
file.close()


--------------------------------------------------------------------------------

5.3　.csv檔:雙迴圈

from urllib import request
from bs4 import BeautifulSoup
import os

#新增一資料夾存放檔案
dir="C:/PyETL"
#檢查:若無則創建、有則存入
if not os.path.exists(dir):
    os.mkdir(dir)
datarow=[]
loc=0

headers={"User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36"}
url="https://www.ptt.cc/bbs/joke/index.html"
req=request.Request(url=url,headers=headers)
res=request.urlopen(req)
soup=BeautifulSoup(res,"html.parser")

#輸出所有文章標題及網址
target=soup.findAll("div",{"class":"title"})
for item in target:
    title=item.a.text
    url="https://www.ptt.cc"+item.a['href']

　　#逐圈增寫一筆(巢狀)列表
    datarow.append([])
    datarow[loc].append(title)
    datarow[loc].append(url)
    loc+=1

file=open("%s/CSV.csv"%(dir),"w",encoding="utf-8")
for rows in datarow:
    #外迴圈writelines:逐項列表輸出
    file.writelines(rows)
    file.write("\n")
file.close()


--------------------------------------------------------------------------------

5.4　.xls檔

from urllib import request
from bs4 import BeautifulSoup
import os
import xlwt

#新增一資料夾存放檔案
dir="C:/PyETL"
#檢查:若無則創建、有則存入
if not os.path.exists(dir):
    os.mkdir(dir)

headers={"User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36"}
url="https://www.ptt.cc/bbs/joke/index.html"
req=request.Request(url=url,headers=headers)
res=request.urlopen(req)
soup=BeautifulSoup(res,"html.parser")

#輸出所有文章標題及網址
target=soup.findAll("div",{"class":"title"})
for item in target:
    title=item.a.text
    url="https://www.ptt.cc"+item.a['href']

    file=open("%s/XLS.xls"%(dir),"a",encoding="utf-8")
    file.write(title+url+"\n")
file.close()


--------------------------------------------------------------------------------

5.5　.xlsx檔

from urllib import request
from bs4 import BeautifulSoup
import os
import openpyxl

#新增一資料夾存放檔案
dir="C:/PyETL"
#檢查:若無則創建、有則存入
if not os.path.exists(dir):
    os.mkdir(dir)

headers={"User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36"}
url="https://www.ptt.cc/bbs/joke/index.html"
req=request.Request(url=url,headers=headers)
res=request.urlopen(req)
soup=BeautifulSoup(res,"html.parser")

#輸出所有文章標題及網址
target=soup.findAll("div",{"class":"title"})
for item in target:
    title=item.a.text
    url="https://www.ptt.cc"+item.a['href']

    file=open("%s/XLSX.xlsx"%(dir),"a",encoding="utf-8")
    file.write(title+url+"\n")
file.close()
