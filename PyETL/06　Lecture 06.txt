
Lecture 06　資料儲檔(2)

--------------------------------------------------------------------------------

6.1　Pandas

from urllib import request
from bs4 import BeautifulSoup
import pandas

#宣告DataFrame，並定義資料欄位
data=pandas.DataFrame(columns=["文章標題", "文章網址"])
#loc=index，以迴圈逐筆寫入資料
loc=0

headers={"User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36"}
url="https://www.ptt.cc/bbs/joke/index.html"
req=request.Request(url=url, headers=headers)
res=request.urlopen(req)
soup=BeautifulSoup(res, "html.parser")

#輸出所有文章標題及網址
target=soup.findAll("div", {"class":"title"})
for item in target:
    title=item.a.text
    url="https://www.ptt.cc"+item.a['href']

　　#列表逐項寫入，迴圈初始須清空
    datarow=[]
    datarow.append(title)
    datarow.append(url)
    data.loc[loc]=datarow
    loc+=1

print(data)


--------------------------------------------------------------------------------

6.2　Pandas+.csv檔

from urllib import request
from bs4 import BeautifulSoup
import pandas
import os

#新增一資料夾存放檔案
dir="C:/PyETL"
#檢查:若無則創建、有則存入
if not os.path.exists(dir):
    os.mkdir(dir)

#宣告DataFrame，並定義資料欄位
data=pandas.DataFrame(columns=["文章標題", "文章網址"])
#loc=index，以迴圈逐筆寫入資料
loc=0

headers={"User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36"}
url="https://www.ptt.cc/bbs/joke/index.html"
req=request.Request(url=url, headers=headers)
res=request.urlopen(req)
soup=BeautifulSoup(res, "html.parser")

#輸出所有文章標題及網址
target=soup.findAll("div", {"class":"title"})
for item in target:
    title=item.a.text
    url="https://www.ptt.cc"+item.a['href']

    #列表逐項寫入，迴圈初始須清空
    datarow=[]
    datarow.append(title)
    datarow.append(url)
    data.loc[loc]=datarow
    loc+=1

data.to_csv("%s/CSV.csv"%(dir), encoding="utf-8")


--------------------------------------------------------------------------------

6.3　Pandas+.xls檔

from urllib import request
from bs4 import BeautifulSoup
import pandas
import os
import xlwt

#新增一資料夾存放檔案
dir="C:/PyETL"
#檢查:若無則創建、有則存入
if not os.path.exists(dir):
    os.mkdir(dir)

#宣告DataFrame，並定義資料欄位
data=pandas.DataFrame(columns=["文章標題", "文章網址"])
#loc=index，以迴圈逐筆寫入資料
loc=0

headers={"User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36"}
url="https://www.ptt.cc/bbs/joke/index.html"
req=request.Request(url=url, headers=headers)
res=request.urlopen(req)
soup=BeautifulSoup(res, "html.parser")

#輸出所有文章標題及網址
target=soup.findAll("div", {"class":"title"})
for item in target:
    title=item.a.text
    url="https://www.ptt.cc"+item.a['href']

    #列表逐項寫入，迴圈初始須清空
    datarow=[]
    datarow.append(title)
    datarow.append(url)
    data.loc[loc]=datarow
    loc+=1

data.to_csv("%s/XLS.xls"%(dir), encoding="utf-8")


--------------------------------------------------------------------------------

6.4　Pandas+.xlsx檔

from urllib import request
from bs4 import BeautifulSoup
import pandas
import os
import openpyxl

#新增一資料夾存放檔案
dir="C:/PyETL"
#檢查:若無則創建、有則存入
if not os.path.exists(dir):
    os.mkdir(dir)

#宣告DataFrame，並定義資料欄位
data=pandas.DataFrame(columns=["文章標題", "文章網址"])
#loc=index，以迴圈逐筆寫入資料
loc=0

headers={"User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36"}
url="https://www.ptt.cc/bbs/joke/index.html"
req=request.Request(url=url, headers=headers)
res=request.urlopen(req)
soup=BeautifulSoup(res, "html.parser")

#輸出所有文章標題及網址
target=soup.findAll("div", {"class":"title"})
for item in target:
    title=item.a.text
    url="https://www.ptt.cc"+item.a['href']

    #列表逐項寫入，迴圈初始須清空
    datarow=[]
    datarow.append(title)
    datarow.append(url)
    data.loc[loc]=datarow
    loc+=1

data.to_csv("%s/XLSX.xlsx"%(dir), encoding="utf-8")
